
## 基于邻域的协同过滤 
* UserCF，ItemCF：向量间距离
UserCF是给用户推荐和他兴趣相似的用户喜欢的物品，ItemCF是给用户推荐他之前喜欢物品的相似物品。协同过滤最核心的内容是基于向量的相似度（向量化召回），所以也存在冷启动问题。

### UserCF与ItemCF
•	UserCF: 推荐和当前用户相似度高的N个用户产生过行为的物品给当前用户
•	ItemCF: 推荐和当前用户历史上行为过的物品相似的物品给当前用户(可解释性强)
•	用户数远大于物品数时，使用采用ItemCF；用户数少于物品数时，使用UserCF更准确
•	如果物品列表经常变换，那么采用UserCF更准确；如果物品列表相对于用户更稳定，那么采用ItemCF
•	在冷启动阶段，UserCF对于新加入的物品能很快进入推荐列表，ItemCF对新加入的用户可以很快进行推荐

![image](https://user-images.githubusercontent.com/68730894/115145650-2f531280-a085-11eb-880d-9430fc8af90a.png)

### 基于用户的协同过滤（UserCF-Based）原理
利用行为相似度计算用户相似度（3种）
* Step1：找到和目标用户兴趣相似的用户集合（含有流行度惩罚）
Jaccard相似度：N(u)，N(v)分别代表用户u和用户v有过正反馈的物品集合
![image](https://user-images.githubusercontent.com/68730894/115145870-768dd300-a086-11eb-9f54-1440f2240903.png)

余弦相似度：∩交集越多，用户之间越相似，![image](https://user-images.githubusercontent.com/68730894/115145876-84dbef00-a086-11eb-878a-5475dd2a5c1a.png)

降权相似度：借用TF-IDF中逆向文档率公式降低热门物品对相似度的影响力

![image](https://user-images.githubusercontent.com/68730894/115145909-b359ca00-a086-11eb-862b-3305972f18a3.png)

* Step2：用户u对物品的相似度==K个邻居对物品i的兴趣度
通过寻找与目标用户u相似兴趣的用户（∩交集）将要推荐物品i有过行为的所有用户，通过用户u和用户v的兴趣相似度（邻居对v的打分）点乘用户v对物品i的兴趣分数，加和上述交集结果之后得到用户u对物品i的相似度。
![image](https://user-images.githubusercontent.com/68730894/115145904-af2dac80-a086-11eb-9601-65fc4f011cdd.png)

S(u, K)表示与用户u兴趣相近的k个用户
N(i)表示对物品i有过行为的所有用户
w_uv表示用户u和用户v的兴趣相似度（邻居对v打分）
r_vi用户v对物品i的兴趣（打分）
p(u,i)用户u对物品i的相似度

* Step3：生成用户u的推荐列表
和用户u兴趣相同的k个邻居喜欢物品汇总，删除用户u已经喜欢过的物品，top-N从大到小推荐。

### 基于物品的协同过滤（ItemCF-based）
利用行为相似度计算物品相似度
* Step1：计算物品间的相似度（距离）
相似度算法：余弦相似度、Jaccard相似度。
N(i)，喜欢物品i的用户数，如果N(j)过大，说明j是热门物品很多人都喜欢，需要对N(j)进行惩罚，避免推荐热门物品

* Step2：用户u对物品i的兴趣 == 物品i的k个邻居物品，收到用户u的兴趣度
![image](https://user-images.githubusercontent.com/68730894/115145937-e3a16880-a086-11eb-8912-9e8edde28493.png)

S(i, K)表示与物品i相近的k个物品
N(u)表示对用户u喜欢物品的集合
w_ij表示物品i和j的相似度（邻居对v打分）
r_uj用户u对物品j的兴趣（打分）
p(u,i)用户u对物品i的相似度

* Step3：生成推荐列表
和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名，预测用户u为物品的兴趣度，去掉已经喜欢过的物品，按照top-N从大到小排序。
![image](https://user-images.githubusercontent.com/68730894/115145940-eac87680-a086-11eb-93dc-8a257c1a9591.png)

### Embedding矩阵的相似度计算
Embedding可视为向量来处理，上述3种相似度计算方法适用于Embedding。用户相似度是计算图中的行向量相似度，商品相似度是计算图中的列向量相似度。
![image](https://user-images.githubusercontent.com/68730894/115145960-0b90cc00-a087-11eb-8fd9-8f10df807864.png)

召回阶段的YouTube推荐系统中使用神经网络训练训练了视频的Embedding，是其网络架构中最后一层隐藏层ReLU的输出结果。
Airbnb召回阶段为房子建立List Embedding，使用Word2Vec的隐藏层作为房子的Embedding，但是word2vec中没有使用激活函数。


### UserCF和ItemCF如何匹配选择
UserCF：推荐当前用户相似度高的n个用户产生过行为的物品给当前用户
ItemCF：推荐和当前用户历史上有过行为物品相似的物品给当前用户（可解释性强）

### 结果对比
* itemCF k=20
RMSE: 0.8658

算法itemCF的平均RMSE Loss为0.866068098574338

花费多长时间 703.9590721130371

* userCF k=20
RMSE: 0.8912 0.8907 0.8893

算法userCF的平均RMSE Loss为0.8903962789409409

花费多长时间 1126.5659790039062

### ItemCF与UserCF的区别
* ItemCF：
成熟期、物品列表比用户稳定

用户数>>物品数，使用ItemCF，用户数多代表用户的历史行为多，
* UseCF：
物品列表经常换，计算复杂度小

用户数<<物品数，推荐与当前用户相似用户产生过行为的物品给当前用户

冷启动：UserCF对于新加入的物品能很快进入推荐列表

* 可解释性好。因为是找邻居，邻居的特点就是类似它的特点
* 邻域方法可以在离线预先计算近邻，通过预先计算好的相似度矩阵（比如：Airbnb 的List Embedding），通过查表(embedding lookup)的方式找出k近邻后就可以对item评分进行预测，推荐过程的实时性强
* 邻居数K是重要参数，k可以通过交叉验证来选择，通常k的取值在20到50之间
* 当用户数和item数巨大时，保存所有的相似度需要大量的存储空间。可以提前进行过滤，去掉不重要的相似度信息(Top-N过滤,阈值过滤,负值过滤)，使用近似最近邻算法
* 冷启动问题，借助可利用的一切数据。直接用UserCF和ItemCF新的user和item找k近邻需要借助其他方法，参考Airbnb（借助上传房源的位置价格房型找到相似的embedding取均值）、热门、其他渠道注册的信息源（比如：微博的关联账号，查找微博的好友关系），调查问卷
* 稀疏问题，不能直接做KNN，当评分矩阵很稀疏时，两个用户共同评分的项会很少，使得预测结果偏差较大。（先用SVD补全矩阵的缺失值，再用KNN。或者直接用KNNBaseline，因为baseline也能学一些内容。或者人工规则建立用户画像：Airbnb中User Type属性及Bucket，使用聚类的想法把用户聚成几个类别）

### 协同过滤的核心是相似邻居KNN（如何定义相似邻居）
K为邻居或者k为半径2种方法，KNN默认的是最近的K个邻居找相似，而不是K为半径的找邻居方法。

找邻居：固定数量的K个邻居，无论距离远近，只取固定的K个最近邻居，按照邻居个数划分。邻居数一定是k，图中所示是k=5。

K-Nearest Neighbor，KNN：基于相似度的邻居，落在以当前点为中心，距离为K的区域内所有点为邻居，K为半径。按照距离划分，邻居数不一定等于5。

** K的取值一般介于20-50之间 ** 
k过小，如果目标点周围有噪音，预测值容易受到噪音的影响。比如：目标点A周围有50个点，包含10个噪音点，如果k=1，k模型正好取到噪音点，预测值就不准确。

K过大：内存容易爆炸，还会拟合跟目标值不相关的内容。

![image](https://user-images.githubusercontent.com/68730894/115146007-4b57b380-a087-11eb-9ddf-4fd66cdc4083.png)



